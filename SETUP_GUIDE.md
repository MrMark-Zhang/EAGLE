# EAGLE å¤šè½®å¯¹è¯è®­ç»ƒé…ç½®æŒ‡å—

## ğŸ“‹ å½“å‰ç¯å¢ƒ

- **Python**: 3.12.3
- **GPU**: NVIDIA RTX PRO 6000 (97GB)
- **ä½ç½®**: /workspace/EAGLE

## âœ… å·²æœ‰æ–‡ä»¶

æ‰€æœ‰è®­ç»ƒä»£ç å·²å°±ç»ªï¼š
- `eagle/traineagle3/main.py` - ä¸»è®­ç»ƒè„šæœ¬ï¼ˆå·²ä¿®æ”¹æ”¯æŒå¤šè½®å¯¹è¯ï¼‰
- `eagle/traineagle3/cnets.py` - æ¨¡å‹å®šä¹‰ï¼ˆå·²ä¿®å¤ï¼‰
- `eagle/traineagle3/modeling_qwen3_kv.py` - Qwen3 æ¨¡å‹ï¼ˆå·²ä¿®å¤ï¼‰
- `eagle/traineagle3/config.json` - æ¨¡å‹é…ç½®ï¼ˆQwen3-8Bï¼‰
- `eagle/traineagle3/ds_config_test.json` - DeepSpeed é…ç½®ï¼ˆBF16ï¼‰

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install torch transformers deepspeed accelerate datasets safetensors wandb
```

### 2. å‡†å¤‡æ•°æ®

åˆ›å»º OpenAI æ ¼å¼çš„è®­ç»ƒæ•°æ®ï¼ˆ`train.jsonl`ï¼‰ï¼š

```json
{"id": "sample_1", "messages": [
  {"role": "user", "content": "ä½ å¥½"},
  {"role": "assistant", "content": "ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"},
  {"role": "user", "content": "ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"},
  {"role": "assistant", "content": "æˆ‘æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹..."}
]}
```

### 3. å‡†å¤‡æ¨¡å‹

ä¸‹è½½ Qwen3-8B æ¨¡å‹æˆ–ä½¿ç”¨å·²æœ‰æ¨¡å‹è·¯å¾„

### 4. å¯åŠ¨è®­ç»ƒ

```bash
cd /workspace/EAGLE/eagle/traineagle3

deepspeed --num_gpus=1 main.py \
    --basepath /path/to/Qwen3-8B \
    --trainpath /path/to/train.jsonl \
    --testpath /path/to/test.jsonl \
    --savedir /workspace/output \
    --model_type qwen3 \
    --data_format openai \
    --deepspeed_config ds_config_test.json
```

## ğŸ“Š æ•°æ®æ ¼å¼

### OpenAI æ ¼å¼ï¼ˆæ¨èï¼‰

```json
{
  "id": "sample_1",
  "messages": [
    {"role": "user", "content": "é—®é¢˜1"},
    {"role": "assistant", "content": "å›ç­”1"},
    {"role": "user", "content": "é—®é¢˜2"},
    {"role": "assistant", "content": "å›ç­”2"}
  ]
}
```

### ShareGPT æ ¼å¼

```json
{
  "id": "sample_1",
  "conversations": [
    {"from": "human", "value": "é—®é¢˜1"},
    {"from": "gpt", "value": "å›ç­”1"}
  ]
}
```

## âš™ï¸ é…ç½®è¯´æ˜

### ä¿®æ”¹è®­ç»ƒè½®æ•°

ç¼–è¾‘ `main.py` ç¬¬ 26 è¡Œï¼š
```python
"num_epochs": 2,  # æ”¹ä¸ºä½ éœ€è¦çš„è½®æ•°
```

### ä¿®æ”¹ batch size

ç¼–è¾‘ `ds_config_test.json`ï¼š
```json
{
  "train_micro_batch_size_per_gpu": 1,
  "gradient_accumulation_steps": 2
}
```

### ä½¿ç”¨ä¸åŒçš„æ¨¡å‹

ç¼–è¾‘ `config.json`ï¼Œæ›´æ–° `vocab_size` ç­‰å‚æ•°ä»¥åŒ¹é…ä½ çš„æ¨¡å‹

## âœ… å·²éªŒè¯åŠŸèƒ½

- âœ… å¤šè½®å¯¹è¯ Loss è®¡ç®—ï¼ˆåªå¯¹ assistant å›ç­”è®¡ç®—ï¼‰
- âœ… OpenAI/ShareGPT æ•°æ®æ ¼å¼æ”¯æŒ
- âœ… Qwen3-8B è®­ç»ƒ
- âœ… BF16 ç²¾åº¦
- âœ… DeepSpeed ZeRO Stage 2

## ğŸ”§ æ•…éšœæ’é™¤

### æ˜¾å­˜ä¸è¶³

å‡å° batch size æˆ–ä½¿ç”¨ ZeRO Stage 3ï¼š
```json
{
  "train_micro_batch_size_per_gpu": 1,
  "zero_optimization": {"stage": 3}
}
```

### ä¾èµ–ç¼ºå¤±

```bash
pip install torch transformers deepspeed accelerate datasets safetensors
```

### æ•°æ®æ ¼å¼é”™è¯¯

ç¡®ä¿ï¼š
- ä½¿ç”¨ JSONL æ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ª JSONï¼‰
- åŒ…å« `messages` æˆ– `conversations` å­—æ®µ
- ä½¿ç”¨æ­£ç¡®çš„ `--data_format` å‚æ•°

---

**é…ç½®å®Œæˆåå³å¯å¼€å§‹è®­ç»ƒï¼**

